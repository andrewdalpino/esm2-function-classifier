{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ac8eb95",
   "metadata": {},
   "source": [
    "Let's start by creating a mapping of gene oncology (GO) term IDS to their label indices for each of the three subgraphs of the gene ontology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2190f932",
   "metadata": {},
   "outputs": [],
   "source": [
    "obo_file_path = \"./dataset/train/go-basic.obo\"\n",
    "\n",
    "bp_terms, cc_terms, mf_terms, all_terms = [], [], [], []\n",
    "\n",
    "with open(obo_file_path, 'r') as file:\n",
    "    data = file.read().split(\"[Term]\")\n",
    "\n",
    "for term_data in data[1:]:  # Skip the first element as it is before the first [Term].\n",
    "    lines = term_data.strip().splitlines()\n",
    "\n",
    "    term_id = None\n",
    "    namespace = None\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith(\"id:\"):\n",
    "            term_id = line.split(\"id:\")[1].strip()\n",
    "        elif line.startswith(\"namespace:\"):\n",
    "            namespace = line.split(\"namespace:\")[1].strip()\n",
    "\n",
    "        if term_id and namespace:\n",
    "            match namespace:\n",
    "                case \"biological_process\":\n",
    "                    bp_terms.append(term_id)\n",
    "                case \"cellular_component\":\n",
    "                    cc_terms.append(term_id)\n",
    "                case \"molecular_function\":\n",
    "                    mf_terms.append(term_id)\n",
    "            \n",
    "            all_terms.append(term_id)\n",
    "\n",
    "            break\n",
    "\n",
    "# Print the first 10 terms.\n",
    "for term_mapping in [all_terms, bp_terms, cc_terms, mf_terms]:\n",
    "    for label_index, term_id in enumerate(term_mapping[:5]):\n",
    "        print(f\"{term_id} => {label_index}\")\n",
    "\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b390991",
   "metadata": {},
   "source": [
    "Next, let's count the number of unique GO terms so we know how many classes we need to represent in the output layer of the Transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5891b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_num_classes = len(all_terms)\n",
    "num_bp_classes = len(bp_terms)\n",
    "num_cc_classes = len(cc_terms)\n",
    "num_mf_classes = len(mf_terms)\n",
    "\n",
    "print(f\"Number of biological process classes: {num_bp_classes:,}\")\n",
    "print(f\"Number of cellular component classes: {num_cc_classes:,}\")\n",
    "print(f\"Number of molecular function classes: {num_mf_classes:,}\")\n",
    "\n",
    "print(f\"Total number of classes: {all_num_classes:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9310c1",
   "metadata": {},
   "source": [
    "Now let's map the sequence IDs to their GO term label indices. We'll also count the GO terms so we can plot them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24a6515",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "terms_path = \"./dataset/train/train_terms.tsv\"\n",
    "\n",
    "all_counter = Counter()\n",
    "bp_counter = Counter()\n",
    "cc_counter = Counter()\n",
    "mf_counter = Counter()\n",
    "\n",
    "# Convert to dict for O(1) label index lookup.\n",
    "all_terms = {term: index for index, term in enumerate(all_terms)}\n",
    "bp_terms = {term: index for index, term in enumerate(bp_terms)}\n",
    "cc_terms = {term: index for index, term in enumerate(cc_terms)}\n",
    "mf_terms = {term: index for index, term in enumerate(mf_terms)}\n",
    "\n",
    "all_seq_to_label_indices = defaultdict(list)\n",
    "bp_seq_to_label_indices = defaultdict(list)\n",
    "cc_seq_to_label_indices = defaultdict(list)\n",
    "mf_seq_to_label_indices = defaultdict(list)\n",
    "\n",
    "df = pd.read_csv(terms_path, sep='\\t')\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    sequence_id = row[\"EntryID\"]\n",
    "    term_id = row[\"term\"]\n",
    "\n",
    "    match row[\"aspect\"]:\n",
    "        case \"BPO\":\n",
    "            label_index = bp_terms[term_id]\n",
    "            bp_seq_to_label_indices[sequence_id].append(label_index)\n",
    "            bp_counter[term_id] += 1\n",
    "        case \"CCO\":\n",
    "            label_index = cc_terms[term_id]\n",
    "            cc_seq_to_label_indices[sequence_id].append(label_index)\n",
    "            cc_counter[term_id] += 1\n",
    "        case \"MFO\":\n",
    "            label_index = mf_terms[term_id]\n",
    "            mf_seq_to_label_indices[sequence_id].append(label_index)\n",
    "            mf_counter[term_id] += 1\n",
    "    \n",
    "    label_index = all_terms[term_id]\n",
    "    all_seq_to_label_indices[sequence_id].append(label_index)\n",
    "    all_counter[term_id] += 1\n",
    "\n",
    "all_first_5 = dict(islice(all_seq_to_label_indices.items(), 5))\n",
    "bp_first_5 = dict(islice(bp_seq_to_label_indices.items(), 5))\n",
    "cc_first_5 = dict(islice(cc_seq_to_label_indices.items(), 5))\n",
    "mf_first_5 = dict(islice(mf_seq_to_label_indices.items(), 5))\n",
    "\n",
    "# Print the first 10 sequence ID to label index mappings.\n",
    "for sequence_to_label_mapping in [all_first_5, bp_first_5, cc_first_5, mf_first_5]:\n",
    "    for sequence_id, label_indices in sequence_to_label_mapping.items():\n",
    "        print(f\"{sequence_id} => {label_indices}\")\n",
    "\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0538ecb",
   "metadata": {},
   "source": [
    "Next thing we'll do is plot the top k GO terms for each subgraph using a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6640654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "top_k = 40\n",
    "\n",
    "for name, counter in [\n",
    "    (\"All\", all_counter),\n",
    "    (\"Biological Process\", bp_counter),\n",
    "    (\"Cellular Component\", cc_counter),\n",
    "    (\"Molecular Function\", mf_counter),\n",
    "]:\n",
    "    counter = dict(sorted(counter.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    first_k = dict(islice(counter.items(), top_k))\n",
    "\n",
    "    plt.figure(figsize=(12, 5)) \n",
    "\n",
    "    plt.bar(first_k.keys(), first_k.values())\n",
    "\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.xlabel(\"GO Term ID\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(f\"Top {top_k} {name} Term Frequencies\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7c1560",
   "metadata": {},
   "source": [
    "Let's read through the training samples and create a new JSONL dataset that contains the raw protein sequences and a list of their GO term label indices for each of the GO subgraphs. This will be the file that we read from when fine-tuning the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ceade3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "fasta_path = \"./dataset/train/train_sequences.fasta\"\n",
    "\n",
    "all_dataset_path = \"./dataset/all_dataset.jsonl\"\n",
    "mf_dataset_path = \"./dataset/mf_dataset.jsonl\"\n",
    "bp_dataset_path = \"./dataset/bp_dataset.jsonl\"\n",
    "cc_dataset_path = \"./dataset/cc_dataset.jsonl\"\n",
    "\n",
    "for dataset_path, sequence_to_label_indices in [\n",
    "    (all_dataset_path, all_seq_to_label_indices),\n",
    "    (mf_dataset_path, mf_seq_to_label_indices),\n",
    "    (bp_dataset_path, bp_seq_to_label_indices),\n",
    "    (cc_dataset_path, cc_seq_to_label_indices),\n",
    "]:\n",
    "    min_seq_length = float(\"inf\")\n",
    "    max_seq_length = 0\n",
    "    total_seq_length = 0\n",
    "    num_sequences = 0\n",
    "\n",
    "    with open(dataset_path, \"w\") as dataset_file:   \n",
    "        with open(fasta_path, \"r\") as fasta_file:\n",
    "            for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "                sequence_id = record.id\n",
    "                sequence = str(record.seq)\n",
    "\n",
    "                label_indices = sequence_to_label_indices[sequence_id]\n",
    "\n",
    "                seq_length = len(sequence)\n",
    "\n",
    "                min_seq_length = min(min_seq_length, seq_length)\n",
    "                max_seq_length = max(max_seq_length, seq_length)\n",
    "                total_seq_length += seq_length\n",
    "\n",
    "                num_sequences += 1\n",
    "\n",
    "                line = {\n",
    "                    \"sequence_id\": sequence_id,\n",
    "                    \"sequence\": sequence,\n",
    "                    \"label_indices\": label_indices\n",
    "                }\n",
    "\n",
    "                dataset_file.write(json.dumps(line) + \"\\n\")\n",
    "\n",
    "    print(f\"Dataset saved to {dataset_path}\")\n",
    "\n",
    "    average_seq_length = total_seq_length / num_sequences\n",
    "\n",
    "    print(f\"Minimum sequence length: {min_seq_length:,}\")\n",
    "    print(f\"Maximum sequence length: {max_seq_length:,}\")\n",
    "    print(f\"Average sequence length: {average_seq_length:.2f}\")\n",
    "\n",
    "    print(f\"Number of sequences: {num_sequences:,}\")\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73eb92a",
   "metadata": {},
   "source": [
    "At inference time, we'll need to map the label index back to the GO term in the graphical structure. For that we can reverse our current mappings and store them as a JSON structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fcbfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_label_mapping_path = \"./dataset/all_label_mapping.json\"\n",
    "bp_label_mapping_path = \"./dataset/bp_label_mapping.json\"\n",
    "cc_label_mapping_path = \"./dataset/cc_label_mapping.json\"\n",
    "mf_label_mapping_path = \"./dataset/mf_label_mapping.json\"\n",
    "\n",
    "all_terms = [term for term in all_terms.keys()]\n",
    "bp_terms = [term for term in bp_terms.keys()]\n",
    "cc_terms = [term for term in cc_terms.keys()]\n",
    "mf_terms = [term for term in mf_terms.keys()]\n",
    "\n",
    "for path, terms in [\n",
    "    (all_label_mapping_path, all_terms),\n",
    "    (bp_label_mapping_path, bp_terms),\n",
    "    (cc_label_mapping_path, cc_terms),\n",
    "    (mf_label_mapping_path, mf_terms),\n",
    "]:\n",
    "    with open(path, \"w\") as file:\n",
    "        file.write(json.dumps(terms) + \"\\n\")\n",
    "\n",
    "        print(f\"Label mapping saved to {path}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
