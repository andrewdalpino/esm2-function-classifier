{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ac8eb95",
   "metadata": {},
   "source": [
    "Let's start by creating a mapping of gene oncology (GO) term IDS to their label indices starting from 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2190f932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO:0000001 => 0\n",
      "GO:0000002 => 1\n",
      "GO:0000003 => 2\n",
      "GO:0000005 => 3\n",
      "GO:0000006 => 4\n",
      "GO:0000007 => 5\n",
      "GO:0000008 => 6\n",
      "GO:0000009 => 7\n",
      "GO:0000010 => 8\n",
      "GO:0000011 => 9\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "obo_file_path = \"./dataset/train/go-basic.obo\"\n",
    "\n",
    "term_to_label_index = {}\n",
    "label_index = 0\n",
    "\n",
    "with open(obo_file_path, 'r') as file:\n",
    "    data = file.read().split(\"[Term]\")\n",
    "\n",
    "for term_data in data[1:]:  # Skip the first element as it is before the first [Term].\n",
    "    lines = term_data.strip().splitlines()\n",
    "\n",
    "    term_id = None\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith(\"id:\"):\n",
    "            term_id = line.split(\"id:\")[1].strip()\n",
    "\n",
    "        if term_id:\n",
    "            term_to_label_index[term_id] = label_index\n",
    "\n",
    "            label_index += 1\n",
    "\n",
    "            break\n",
    "\n",
    "first_10 = dict(islice(term_to_label_index.items(), 10))\n",
    "\n",
    "# Print the first 10 terms.\n",
    "for term_id, label_index in first_10.items():\n",
    "    print(f\"{term_id} => {label_index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b390991",
   "metadata": {},
   "source": [
    "Next, let's count the number of unique GO terms so we know how many classes we need to represent in the output layer of the Transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d5891b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of classes: 47,417\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(term_to_label_index)\n",
    "\n",
    "print(f\"Total number of classes: {num_classes:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9310c1",
   "metadata": {},
   "source": [
    "Now we can map the sequence IDs to their GO term label indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a24a6515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0A009IHW8 => [6130, 17759, 33427, 21998, 5218, 40751, 21979, 40817, 6129, 41016, 41017, 6987, 4668, 22006, 23863, 12080, 23851, 28851, 21986, 12152, 12342, 5265, 12378, 40818, 4687, 24055, 7801, 5194, 5254, 17745, 33425, 32690, 12082, 41027, 33430, 23803, 7033, 33428, 4719, 6928, 21980, 5251, 12375, 2628, 2856, 10504, 10514, 10513, 2743]\n",
      "A0A021WW32 => [26053, 26041, 13187, 31037, 5667, 5473, 36072, 20451, 25726, 6129, 42410, 5777, 8384, 26872, 25678, 11949, 13523, 241, 25679, 546, 13220, 25921, 38541, 5464, 25889, 7710, 10126, 15704, 29141, 7801, 9891, 32815, 5475, 8407, 12883, 5477, 25528, 5421, 53, 239, 13550, 15703, 8264, 25857, 31227, 27340, 32681, 36345, 191, 4204, 21059, 524, 527, 521, 21064, 16155, 21062, 21065, 4215, 4278, 21061, 15210, 525, 35953, 21066, 4273, 4160, 22479, 4268, 526, 6245, 38223, 4289, 31051, 21060, 515, 15204]\n",
      "A0A023FFD0 => [29188, 7783, 31037, 8427, 29186, 13372, 6129, 46282, 8265, 27171, 26997, 26872, 8425, 26995, 21852, 39621, 26876, 7781, 25785, 19984, 15325, 13366, 31039, 39637, 27169, 13696, 21194, 25731, 39636, 25727, 25787, 39620, 19983, 46283, 15326, 13698, 15315, 12626, 12625, 4089, 2628, 12624, 4107]\n",
      "A0A023GPJ3 => [24212, 31038, 13366, 31037, 2037, 8427, 13372, 42869, 27118, 27121, 27123, 6129, 34569, 2036, 8587, 34390, 26872, 8425, 25731, 25727, 34571, 16047, 27120, 42870, 24207, 26876, 4305, 4390, 4160, 4204, 38223]\n",
      "A0A023GPK8 => [34868, 18108, 1031, 19974, 34473, 15704, 26875, 18107, 26041, 31037, 5667, 20284, 7485, 7704, 6129, 25792, 6322, 949, 2198, 46165, 26872, 26063, 25936, 15703, 25921, 5767, 25721, 39354, 5798, 13238]\n",
      "A0A023GQ97 => [32464, 27744, 5659, 31038, 7801, 7460, 13367, 31037, 7267, 9903, 5995, 36488, 5993, 6129, 37686, 32618, 36175, 26971, 32470, 18323, 7173, 7474, 5555, 15703, 20333, 32202, 5971, 5660, 32468, 36489]\n",
      "A0A023GRW4 => [13394, 16153, 7441, 19982, 7782, 25858, 26053, 26041, 13371, 5667, 6031, 7485, 25726, 13408, 20200, 22715, 5564, 26872, 25678, 25786, 20279, 13523, 35475, 18166, 16154, 25921, 7781, 25998, 32815, 33303, 5790, 38258, 38256, 30416, 18168, 15703, 25857, 6037, 569, 13187, 31037, 571, 5786, 6129, 5789, 5777, 47359, 26971, 8425, 14461, 47361, 26876, 25889, 25785, 30108, 6030, 15704, 7801, 9891, 13366, 8426, 22713, 5375, 26043, 5785, 13550, 25730]\n",
      "A0A023GU64 => [31929, 26041, 25893, 20877, 5667, 7485, 7704, 25895, 25770, 13408, 6129, 21846, 25796, 819, 25764, 25894, 38251, 25921, 25721, 13409, 15704, 25891, 7801, 9891, 7617, 32815, 38256, 22454, 29157, 5421, 44164, 15703, 7619, 25896, 13242]\n",
      "A0A023GU65 => [31929, 26041, 25893, 20877, 5667, 7485, 7704, 25895, 25770, 13408, 6129, 21846, 25796, 819, 25764, 25894, 38251, 25921, 25721, 13409, 15704, 25891, 7801, 9891, 7617, 32815, 38256, 22454, 29157, 5421, 44164, 15703, 7619, 25896, 13242]\n",
      "A0A023GUT0 => [7710, 20274, 29141, 27311, 14581, 31037, 1212, 23312, 26819, 25726, 1210, 6129, 34053, 26820, 8346, 11947, 8384, 26872, 27310, 14583, 11949, 27242, 14657, 14655, 27245, 20276, 20435, 20434, 26876, 27244, 25730, 38223, 4160, 4161, 4198, 3833, 2628, 4089, 45637, 4107]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "terms_path = \"./dataset/train/train_terms.tsv\"\n",
    "\n",
    "sequence_to_label_indices = defaultdict(list)\n",
    "\n",
    "df = pd.read_csv(terms_path, sep='\\t')\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    sequence_id = row[\"EntryID\"]\n",
    "    label_index = term_to_label_index[row[\"term\"]]\n",
    "\n",
    "    sequence_to_label_indices[sequence_id].append(label_index)\n",
    "\n",
    "first_10 = dict(islice(sequence_to_label_indices.items(), 10))\n",
    "\n",
    "# Print the first 10 terms.\n",
    "for term_id, label_indices in first_10.items():\n",
    "    print(f\"{term_id} => {label_indices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7c1560",
   "metadata": {},
   "source": [
    "Finally, let's read through the training samples and create a new JSONL dataset that contains the raw protein sequences and a list of their GO term label indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57ceade3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to ./dataset/dataset.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "fasta_path = \"./dataset/train/train_sequences.fasta\"\n",
    "dataset_path = \"./dataset/dataset.jsonl\"\n",
    "\n",
    "with open(dataset_path, \"w\") as dataset_file:   \n",
    "    with open(fasta_path, \"r\") as fasta_file:\n",
    "        for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "            sequence_id = record.id\n",
    "            sequence = str(record.seq)\n",
    "\n",
    "            if sequence_id in sequence_to_label_indices:\n",
    "                label_indices = sequence_to_label_indices[sequence_id]\n",
    "\n",
    "                line = {\n",
    "                    \"sequence_id\": sequence_id,\n",
    "                    \"sequence\": sequence,\n",
    "                    \"label_indices\": label_indices\n",
    "                }\n",
    "\n",
    "                dataset_file.write(json.dumps(line) + \"\\n\")\n",
    "\n",
    "print(f\"Dataset saved to {dataset_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
